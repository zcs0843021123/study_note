# 数据采集与网络爬虫

# 数据采集
如何对数据Feature进行思考
```
现有数据的Feature是否充分？
比如量化投资，基于大数据预测未来股票的波动，根据预测结果进行股票买卖
Thinking：如果有以往股票的所有历史数据，是否可以根据这些数据做出一个预测率高的数据分析系统呢？

AR, MA, ARMA ,ARIMA, LSTM
Time Series Analysis，量化投资的基本技术

现有数据的Feature是否充分？
一个数据的走势，是由多个维度影响的。需要通过多源的数据采集，收集到尽可能多的数据维度，同时保证数据的质量 => 收集到的Feature越充分，得到的数据挖掘结果质量越高
我们是否可以收集到足够数据足够多的Feature？
我们身处市场之中，很难跳脱出来，站在上帝视角了解全面的信息
依然可以找到更多的Feature，没有最多，只有更多
当我们了解越多，越能知道真相，当然这也是有成本


```

数据源都有哪些维度

```

我们从哪些维度可以收集数据？
1、开放数据源
一般针对行业的数据库，比如美国人口调查局开放了美国的人口信息、地区分布和教育情况数据。除了政府外，企业和高校也会开放相应的大数据
很多研究都是基于开放数据集进行的，比如MovieLens，
Netflix Prize DataSet，LETOR，MSLR，Yahoo Learning to Rank数据集等

2、爬虫抓取
爬虫工具，可视化易操作
爬虫代码，自己编写，抓取特定网站或App
3、传感器
比如无人驾驶的传感器数据，新零售的传感器数据，采集的是物理信息（图像、视频、或者某个物体的速度、热度、压强等）
4、日志采集
用于统计用户的操作。可以在前端进行埋点，或在后端进行脚本收集、统计，来分析网站的访问情况，使用瓶颈等


单位	数据源	网址
美国人口调查局	提供人口信息，地区分布和教育情况等美国公民相关的数据	http://www.census.gov/data.html
欧盟	欧盟开放数据平台，提供欧盟各机构的大量数据。	http://open-data.europa.eu/en/data/
Facebook	Facebook官方提供的API，用于查询用户公开的海量信息	https://developers.facebook.com/docs/graph-api
Amazon	亚马逊网络服务开放数据集	http://aws.amazon.com/datasets
Google	谷歌金融，收录了40年以来的股票数据，实时更新	https://www.google.com/finance
北京大学	北京大学开放研究数据平台	http://opendata.pku.edu.cn/
ImageNet	目前世界上图像识别最大的数据库，包括近1500万张图像	http://www.image-net.org/

数据集	说明	网址
MovieLens	电影推荐系统数据集，包括多个大小的版本	https://grouplens.org/datasets/movielens/
Netflix Prize DataSet	1亿部电影评分，Netflix悬赏100万美金的知名数据集	https://www.netflixprize.com/
LETOR	信息检索数据集	https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/
MSLR	微软发布的Learning to Rank数据集	https://www.microsoft.com/en-us/research/project/mslr/
Yahoo LTR	雅虎发布的LTR比赛数据集	http://webscope.sandbox.yahoo.com/**

https://dwz.cn/QzQGw9PN

数据源：丁香园 
https://lab.isaaclin.cn/nCoV/
全国疫情概览： /nCoV/api/overall
省份、地区列表： /nCoV/api/provinceName
地区的疫情数据：/nCoV/api/area
疫情相关新闻：/nCoV/api/news
疫情相关谣言：/nCoV/api/rumors

爬虫抓取工具
火车采集器
14年历史，老牌采集工具。不仅可以做抓取工具，也可以做数据清洗、数据分析、数据挖掘、可视化等工作。数据源适用于绝大部分的网页，网页中能看到的内容都可以通过采集规则进行抓取
搜集客
完全可视化操作，无需编程。采集过程所见即所得，抓取结果信息、错误信息等都反应在软件中。没有流程的概念，用户只需要关注抓取什么数据，而流程细节完全交给集搜客来处理。所有爬虫需要在用户自己电脑上跑

爬虫抓取工具
八爪鱼
知名采集工具，分为免费采集模板，云采集（付费）。
免费的采集模板实际上就是内容采集规则，包括了电商类、生活服务类、社交媒体类、论坛类的网站都可以采集，用起来非常方便。也可以自己来自定义任务。
云采集，就是当你配置好采集任务，就可以交给云端进行采集。八爪鱼一共有5000台服务器，通过云端多节点并发采集，采集速度远远超过本地采集。此外还可以自动切换多个 IP，避免IP被封影响采集

传感器
传感器采集是基于特定的设备，采集和交互信息，包括图像，语音，温度，重量，测速
AIot（人工智能物联网）=AI（人工智能）+Iot（物联网）
场景：智能家居，医疗，会议，交通等
美的的iot战略

日志采集
最大的作用，就是分析用户访问情况，对用户历史行为进行挖掘，同时能及时发现系统承载瓶颈，提高系统负载量，方便基于用户实际用户访问需求进行优化
日志采集是运维人员的重要工作，可以采集用户访问网站的全过程：哪些人在什么时间，通过什么渠道（比如搜索引擎、网址输入）来过，都执行了哪些操作；系统是否产生了错误；甚至包括用户的IP、HTTP请求的时间，用户代理等。这些日志数据可以被写在一个日志文件中，也可以分成不同的日志文件，比如访问日志、错误日志等

日志采集可以分两种形式
通过Web服务器采集，例如 httpd、Nginx、Tomcat 都自带日志记录功能。同时很多互联网企业都有自己的海量数据采集工具，多用于系统日志采集，如Hadoop的Chukwa、Cloudera的Flume、Facebook的Scribe等，这些工具均采用分布式架构，能够满足每秒数百MB的日志数据采集和传输需求
自定义采集用户行为，例如用JavaScript代码监听用户的行为、AJAX异步请求后台记录日志等，比如Google Analysis

日志采集
日志采集有助于我们了解用户的操作行为，对于业务分析，行为预测，运维监控等场景很有帮助
一般Web服务器会自带日志功能，也可以使用Flume从不同的服务器集群中采集、汇总和传输大容量的日志数据
也可以使用第三方的统计工具或自定义埋点得到自己想要的统计内容
不要重复造轮子，基于业务场景选择适合的轮子（工具）
```

Project A：安居客房价抓取

```
数据源：
https://beijing.anjuke.com/
https://beijing.anjuke.com/community/
城市，小区名称，地址，竣工日期，房价，环比上月，网址

简易采集：
使用简便，所见即所得
基本上不需要写代码，除了正则表达式匹配使用到XPath
使用简易采集选择模板即可
输入想要采集的网址，比如https://beijing.anjuke.com/ https://shanghai.anjuke.com/ 
采集结束后，导出数据到csv

简易采集：
优点：方便，直接选择模板即可
不足：效率不高，无法定制采集需求

自定义采集：
按照需求定制采集任务
采集内容使用到XPath
不足：多线程效率不高，反爬虫

```

Project B：抓取微博上关于LightGBM的内容

```
数据源：
https://weibo.com/
搜索指定关键词，如 LightGBM
对搜索到含有LightGBM关键词的微博内容进行抓取
```

如何使用八爪鱼进行数据采集

```

自定义采集：
Step1，输入网址
新建任务时，这里是必填项
Step2，设计流程
这个步骤最为关键，你需要工具，你是如何操作页面的、想要提取页面上的哪些信息等。因为数据条数比较多，通常你还需要翻页，所以要进行循环翻页的设置
Step3，启动采集
当设计好采集流程后，就可以启动采集任务了，任务结束后，会提示你保存采集好的数据，通常是xlsx或csv格式

自定义采集：
步骤包括：基本步骤和高级步骤
基本步骤
打开网页，默认第一项就是需要你输入网址
点击元素，元素的定义比较广泛，它可以是某个按钮，或者某个链接，也可以是某个图片或文字
使用这个步骤是你在搜索或者提交某个请求。当你点击元素后，工具会提示你想要达到的目的：点击该按钮、采集该元素文本、还是鼠标移到该链接上。然后再选择“点击该按钮”进行确认即可
如果我们点击某个元素的目的是循环翻页，或者提取数据，那么在点击之后，工具也会确认你的目的

循环翻页，很多数据都存在翻页的情况，通常你需要找到翻页的位置，比如“下一页”按钮
提取数据，在网页上选择你想要提取的页面范围，鼠标移动到页面上会呈现蓝色的阴影面积，它表明了你想提取的数据范围。然后点击鼠标后，在右侧选择“采集数据”

使用八爪鱼采集安居客房价
Step1，输入网页，https://beijing.anjuke.com/community/
Step2，设置翻页，点击下一页按钮，然后在右侧栏中选择“循环点击下一页”
通常，可以先将流程设置完成后，再通过流程视图，XPath进行细节调整

使用八爪鱼采集安居客房价
Step3，提取数据
选择元素：选中小区名称，地址，均价，环比上月，建造年代等元素
重命名：将列名进行命名（原列名 字段1_文本）
调整元素：使用流程视图，对建造年代进行XPath调整

流程视图：
将之前的操作以流程图的方式展示出来，使用频率较高，方便查看创建流程，调整顺序，或者删掉不想要的步骤
可以在视图中查看数据提取的字段。选中“提取数据”步骤，可以看到该步骤提取的字段都有哪些。一般都会出现很多冗余的字段，因为HTML代码段中会有很多隐藏的内容也会被提取到，这里你可以删掉没用的字段，把保留的字段名称进行备注修改

XPath：
在流程试图中，可以查看元素XPath（XML Path），并对它们进行调整
八爪鱼内置XPath引擎，我们在用可视化方式选择元素的时候，会自动生成相应的XPath
Tips：调整XPath是因为有时候我们采集的网站页面是不规律的，比如第一页和第二页的HTML排版是不同的，这样可视化操作得到的XPath可能不具备通用性，这种情况下就需要人工进行调整（点击循环翻页后，会显示第二个页面，比如微博搜索页面第一页，第二页排版不同，XPath可能发生变化）
常用的两种XPath：循环中的XPath，提取数据的XPath

XPath Helper：
当需要调整XPath时，使用XPath Helper插件方便捕捉指定元素的XPath
安装插件后，可以使用Ctrl + Shift + X 进行快捷启动

Step4，启动本地采集：
一般第三方工具都是收费的，数据量不大的情况下，可以使用免费的本地采集
采集会自动进行翻页，数据提取

启动本地采集：
数据可以导出为csv格式
后续还需要对字段进行处理，比如区域提取，[朝阳区-酒仙桥] => 朝阳区

流程步骤：
Step1，输入网址 https://weibo.com
第一次使用用户名，密码登录后，浏览器会自动记住登录状态，下次不需要输入用户名，密码
Step2，输入想要搜索的内容，比如LightGBM
输入框中输入文本，点击链接
Step3，设置翻页，点击下一页（选择循环点击下一页）
Step4，点击想要抓取的微博内容，采集选中元素的文本
并没有自动抓到页面内其他相同的元素，因此我们需要手动调整
Step5，通过流程视图进行调整
添加循环（设置循环方式=>不固定元素列表）

流程步骤：
Step6，通过XPath Helper获取页面元素的XPath
原有的元素XPath：//DIV[@id='pl_feedlist_index']/DIV[1]/DIV[1]/DIV[1]/DIV[1]/DIV[2]/P[1]
作为提示，尝试改成//DIV[@id='pl_feedlist_index']/DIV/DIV/DIV/DIV/DIV/P[1] 可以匹配到更多的元素（20个）
使用Chrome检查元素，精细调整
//DIV[@id='pl_feedlist_index']/DIV/DIV/DIV/DIV/DIV[@class='content']

流程步骤：
Step7，设置循环页面中的XPath
//DIV[@id='pl_feedlist_index']/DIV/DIV/DIV/DIV/DIV[@class='content']
设置提取元素中的XPath，以及高级选项中的采集当前循环中的元素

流程步骤：
Step8，启动本地采集，导出微博内容到csv文件

Python爬虫工具：
BeautifulSoup，Python Html 解析库，BeautifulSoup 将复杂 HTML 文档转换成一个复杂的树形结构，每个节点都是 Python 对象。
Selenium，Web应用的自动测试工具，可以直接运行在浏览器中，原理是模拟用户在进行操作，支持当前多种主流的浏览器
Scrapy，Python爬虫框架，把基础爬虫功能抽象出来做成的脚手架，Selenium可以应用在Scrapy爬虫框架中
Puppeteer，可以控制Headless Chrome，即无界面的自动化测试框架，支持模拟键盘输入、截图、表单提交等特殊场景操作，Google2018年推出的爬虫神器

抓取安居客北京二手房的信息
Step1，确定URL，https://beijing.anjuke.com/sale/p1
Step2，确定要提取的元素
标题name，详细信息 details，地址 address，标签 tags
经纪人broker ，总价 price，每平米价格 unit
Step3，基于要提取的元素，定位html的标签

import requests
from bs4 import BeautifulSoup
# 请求URL
url = 'https://beijing.anjuke.com/sale/p1'
# 得到页面的内容
headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'}
html=requests.get(url,headers=headers,timeout=10)
content = html.text
# 通过content创建BeautifulSoup对象
soup = BeautifulSoup(content, 'html.parser', from_encoding='utf-8')

#输出第一个 title 标签
print(soup.title)
#输出第一个 title 标签的标签名称
print(soup.title.name)
#输出第一个 title 标签的包含内容
print(soup.title.string)

输出结果：
<title>北京二手房房产网，北京二手房交易信息，北京二手房出售 - 58安居客</title>
title
北京二手房房产网，北京二手房交易信息，北京二手房出售 - 58安居客
```


# 推荐系统OverView
什么是推荐系统

```

推荐系统是一种 信息过滤 系统，根据用户的历史行为、社交关系、兴趣点
算法可以判断用户当前感兴趣的物品或内容。你也可以将它理解为一家只为你而开的商店。店铺里摆放的都是你需要的，或者适合你的商品。

亚马逊CEO贝索斯说：如果我们有100万用户，我们将给他们100万个亚马逊网站

Content-based Filtering
最早人们使用的是基于内容的推荐方法，根据物品的属性为他们打上标签
再通过这些标签计算他们之间的相似度

Collaborative Filtering
协同过滤就是通过数据找到与你相似的用户，通过他们的行为和他们喜欢的内容。为你推荐你可能感兴趣的物品或内容
日常生活中，我们也会找到兴趣相同的朋友来帮我们推荐电影或者音乐

Using data to solve problems
在推荐系统中，Using data重在“相似度”，Solve problems在于“推荐”
Thinking：data可以是物品本身的，也可以是基于用户行为的
物品本身：Content-based 基于物品本身的内容，而不是用户购买/浏览物品的行为
用户行为：
显性反馈数据：用户明确表示对物品的喜欢行为：评分，喜欢，收藏，购买
隐性反馈数据：不能明确反映用户喜好的行为：浏览，停留时间，点击

如何评判“相似”
User-based，两个人共同喜欢的东西越多，那么两个人就越相似
Item-based，两个物品共同喜欢的人越多，这两个物品就越相似

如何进行“推荐”
UserCF，和你兴趣相投的用户，推荐他们喜欢的商品
ItemCF，给用户推荐那些和他们之前喜欢的物品相似的物品
（ItemCF不利用物品的内容属性计算物品之间的相似度，主要通过分析用户的行为记录计算物品之间的相似度）

Using data to recommendation
Thinking: 如果没有大量的data怎么办？
=>冷启动问题：
用户冷启动：新用户来的时候，如何推荐
物品冷启动：新的物品，如何推荐
系统冷启动：新的网站上线，如何推荐


```

Exploit&Explore问题

```

选餐厅：
Exploitation : 去最喜欢的餐厅
Exploration: 尝试新餐厅

浏览内容：
Exploitation: 展示以往感兴趣的内容
Exploration: 展示多样性的内容
 
在线广告:
Exploitation: 展示最好的广告
Exploration: 展示些不同的广告

 	优点	不足
Exploit	充分利用已有的资源	"信息茧房
（信息圈养）"
Explore	认知未知的世界，开疆辟土	准确率低

背景：一家赌场里有多台老虎机（K台），每次摇动都可能获得一定金额的奖励，或者遗憾（regret）
目标：你需要通过选择不同的老虎机臂，最大化自己的利益
（最原始的多臂老虎机问题，每个臂可获得的收益是一定的，不随着用户特征和上下文环境的变化而变化）

Thinking：在线广告：如何进行广告投放，收益最大化？
对于固定流量来说，Exploit的这部分流量显然会产生收益，而Explore不一定能立刻就有收益。所以，如何分配E&E流量才能最大化收益呢
Thinking 冷启动问题：对于新用户时，如何通过若干次实验，猜出用户的大致兴趣？

Bandit算法解决冷启动：
如果用户对推荐的某个Topic感兴趣，就代表获得了收益。否则就表示遗憾
“选择-观察-更新-选择”的循环，将收益最大化
通过几次试验，刻画出新用户心中对每个Topic的感兴趣概率

累积后悔：每次选择后，计算和最佳的选择差了多少，然后把差距累加起来就是总的遗憾

Bandit算法有哪些：Epsilon-Greedy，Thompson sampling，UCB，LinUCB

UCB算法（Upper Confidence Bound）：
用于在Select过程中，判断节点的价值，每次选择选取最大的UCB节点：

Q(s,a)代表蒙特卡洛树中已探索的值
P值是先验概率，是由神经网络计算得到的值
N是这个action的探索次数，c用于调节探索与利用的超参数
对于没有探索的action，和已经探索很多次但是探索反馈很高的action都会有较大的UCB值

MCTS（蒙特卡洛搜索树）是一种通用博弈算法 => 它不需要任何有关博弈的先验知识
MCTS是在UCB算法基础上提出的：
Selection，从根节点状态出发，迭代地使用UCB算法选择最优策略，直到碰到一个叶子节点
Expansion，对叶子节点进行扩展。选择其一个从未访问过的子节点加入当前的搜索树
Simulation，从扩展的新节点出发，进行模拟，直到博弈结束
Back-propagation，更新博弈树中所有节点的状态。进入下一轮的选择和模拟


Thinking：对目标定义的不同，导致了不同的推荐结果

通过Exploit & Explore会给推荐系统带来惊喜度
惊喜度只是推荐系统的目标之一，从评测指标来看包括了：

推荐系统的评价标准：
准确度：打分系统，top N推荐
覆盖率：对物品长尾的发掘能力
多样性：推荐列表中物品两两之间的不相似性
新颖度：给用户suprise
惊喜度：推荐和用户历史兴趣不相似，却满意的
信任度：提供可靠的推荐理由
实时性：实时更新程度

CTR : 点击率（点击量/展示量）
CVR : 转化的情况，商家关注的指标（转化量/点击量）
GPM : 平均1000次展示，平均成交金额

目标很多，我们到底要选择哪个作为指标
不同场景，推荐需求不同

推荐系统是一种信息过滤系统

A 数据源——
	item特征，用户画像，用户行为
B 召回阶段——
	粗筛，得到候选物品集
C 排序阶段——
对多个召回通道的内容进行打分排序，选出最优的少量结果。兼顾推荐系统的多维度指标：覆盖率，多样性，新颖度

不是所有的系统都需要推荐系统

哪些情况下不需要推荐系统？
（一个创业项目刚开始启动，用户数在1000人，item在1万，需要协同过滤进行推荐么？）

如果给一个视频打标签，视频中有音乐作为背景音乐，采用了NLP方式对内容自动打标签，可能存在什么问题？


```

推荐系统的评价指标有哪些

```
```

如果让你推导推荐系统的架构，你会如何设计

```
```

为什么有些方法在工作中会不work

```
```